{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc497a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9defa4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['broke', 'good', 'shift']\n",
      "train Dataset size: 15150\n",
      "test Dataset size: 29\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "num_epochs = 40\n",
    "momentum=0.9\n",
    "weight_decay=1e-5\n",
    "batch_size_train=256\n",
    "batch_size_test=256\n",
    "batch_size = 256\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# 加載數據集\n",
    "train_dataset = ImageFolder(root='/root/notebooks/nfs/work/barry.chen/DenoisingDiffusionProbabilityModel-ddpm-/dataset/only_group1_add', transform=transform)\n",
    "test_dataset = ImageFolder(root='/root/notebooks/nfs/work/barry.chen/DenoisingDiffusionProbabilityModel-ddpm-/dataset/broke_F1210', transform=transform_test)\n",
    "# test_dataset = ImageFolder(root='/root/notebooks/nfs/work/barry.chen/Phison/Conditional_Diffusion/CDDIM/select', transform=transform)\n",
    "# # 創建 DataLoader\n",
    "# # 分割數據集\n",
    "# train_size = int(0.8 * len(dataset))  # 假設80%用於訓練\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 創建 DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# 檢查數據集的類別\n",
    "classes = train_dataset.classes\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "\n",
    "# 顯示數據集的大小\n",
    "print(\"train Dataset size:\", len(train_dataset))\n",
    "print(\"test Dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65da37dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n",
      "Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \",device)\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ad255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic Block for resnet 18 and resnet 34\n",
    "    \"\"\"\n",
    "\n",
    "    #BasicBlock and BottleNeck block\n",
    "    #have different output size\n",
    "    #we use class attribute expansion\n",
    "    #to distinct\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        #residual function\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "        )\n",
    "\n",
    "        #shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        #the shortcut output dimension is not the same with residual function\n",
    "        #use 1*1 convolution to match the dimension\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.LeakyReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"Residual block for resnet over 50 layers\n",
    "    \"\"\"\n",
    "    expansion = 2\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.LeakyReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_block, num_classes=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True))\n",
    "        #we use a different inputsize than the original paper\n",
    "        #so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the\n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may\n",
    "        contain more than one residual block\n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "\n",
    "        # we have num_block blocks per layer, the first block\n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = self.dropout(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "def resnet18():\n",
    "    \"\"\" return a ResNet 18 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def resnet34():\n",
    "    \"\"\" return a ResNet 34 object\n",
    "    \"\"\"\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\" return a ResNet 50 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 6, 3])\n",
    "\n",
    "def resnet101():\n",
    "    \"\"\" return a ResNet 101 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    \"\"\" return a ResNet 152 object\n",
    "    \"\"\"\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11604e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152()\n",
    "model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 3),\n",
    "    )\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96583c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b8cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 0/60\n",
      "epoch: 0 7/60\n",
      "epoch: 0 14/60\n",
      "epoch: 0 21/60\n",
      "[1,    25] loss: 0.345\n",
      "epoch: 0 28/60\n",
      "epoch: 0 35/60\n",
      "epoch: 0 42/60\n",
      "[1,    50] loss: 0.351\n",
      "epoch: 0 49/60\n",
      "epoch: 0 56/60\n",
      "Accuracy train 83 %\n",
      "Accuracy test 44 %\n",
      "epoch: 1 0/60\n",
      "epoch: 1 7/60\n",
      "epoch: 1 14/60\n",
      "epoch: 1 21/60\n",
      "[2,    25] loss: 0.458\n",
      "epoch: 1 28/60\n",
      "epoch: 1 35/60\n",
      "epoch: 1 42/60\n",
      "[2,    50] loss: 0.313\n",
      "epoch: 1 49/60\n",
      "epoch: 1 56/60\n",
      "Accuracy train 84 %\n",
      "Accuracy test 51 %\n",
      "epoch: 2 0/60\n",
      "epoch: 2 7/60\n",
      "epoch: 2 14/60\n",
      "epoch: 2 21/60\n",
      "[3,    25] loss: 0.474\n",
      "epoch: 2 28/60\n",
      "epoch: 2 35/60\n",
      "epoch: 2 42/60\n",
      "[3,    50] loss: 0.325\n",
      "epoch: 2 49/60\n",
      "epoch: 2 56/60\n",
      "Accuracy train 85 %\n",
      "Accuracy test 65 %\n",
      "epoch: 3 0/60\n",
      "epoch: 3 7/60\n",
      "epoch: 3 14/60\n",
      "epoch: 3 21/60\n",
      "[4,    25] loss: 0.435\n",
      "epoch: 3 28/60\n",
      "epoch: 3 35/60\n",
      "epoch: 3 42/60\n",
      "[4,    50] loss: 0.299\n",
      "epoch: 3 49/60\n",
      "epoch: 3 56/60\n",
      "Accuracy train 85 %\n",
      "Accuracy test 58 %\n",
      "epoch: 4 0/60\n",
      "epoch: 4 7/60\n",
      "epoch: 4 14/60\n",
      "epoch: 4 21/60\n",
      "[5,    25] loss: 0.436\n",
      "epoch: 4 28/60\n",
      "epoch: 4 35/60\n",
      "epoch: 4 42/60\n",
      "[5,    50] loss: 0.299\n",
      "epoch: 4 49/60\n",
      "epoch: 4 56/60\n",
      "Accuracy train 85 %\n",
      "Accuracy test 58 %\n",
      "epoch: 5 0/60\n",
      "epoch: 5 7/60\n",
      "epoch: 5 14/60\n",
      "epoch: 5 21/60\n",
      "[6,    25] loss: 0.422\n",
      "epoch: 5 28/60\n",
      "epoch: 5 35/60\n",
      "epoch: 5 42/60\n",
      "[6,    50] loss: 0.328\n",
      "epoch: 5 49/60\n",
      "epoch: 5 56/60\n",
      "Accuracy train 85 %\n",
      "Accuracy test 37 %\n",
      "epoch: 6 0/60\n",
      "epoch: 6 7/60\n",
      "epoch: 6 14/60\n",
      "epoch: 6 21/60\n",
      "[7,    25] loss: 0.445\n",
      "epoch: 6 28/60\n",
      "epoch: 6 35/60\n",
      "epoch: 6 42/60\n",
      "[7,    50] loss: 0.306\n",
      "epoch: 6 49/60\n",
      "epoch: 6 56/60\n",
      "Accuracy train 86 %\n",
      "Accuracy test 68 %\n",
      "epoch: 7 0/60\n",
      "epoch: 7 7/60\n",
      "epoch: 7 14/60\n",
      "epoch: 7 21/60\n",
      "[8,    25] loss: 0.396\n",
      "epoch: 7 28/60\n",
      "epoch: 7 35/60\n",
      "epoch: 7 42/60\n",
      "[8,    50] loss: 0.289\n",
      "epoch: 7 49/60\n",
      "epoch: 7 56/60\n",
      "Accuracy train 85 %\n",
      "Accuracy test 51 %\n",
      "epoch: 8 0/60\n",
      "epoch: 8 7/60\n",
      "epoch: 8 14/60\n",
      "epoch: 8 21/60\n",
      "[9,    25] loss: 0.419\n",
      "epoch: 8 28/60\n",
      "epoch: 8 35/60\n",
      "epoch: 8 42/60\n",
      "[9,    50] loss: 0.280\n",
      "epoch: 8 49/60\n",
      "epoch: 8 56/60\n",
      "Accuracy train 86 %\n",
      "Accuracy test 58 %\n",
      "epoch: 9 0/60\n",
      "epoch: 9 7/60\n",
      "epoch: 9 14/60\n",
      "epoch: 9 21/60\n",
      "[10,    25] loss: 0.405\n",
      "epoch: 9 28/60\n",
      "epoch: 9 35/60\n",
      "epoch: 9 42/60\n",
      "[10,    50] loss: 0.281\n",
      "epoch: 9 49/60\n",
      "epoch: 9 56/60\n",
      "Accuracy train 87 %\n",
      "Accuracy test 65 %\n",
      "epoch: 10 0/60\n",
      "epoch: 10 7/60\n",
      "epoch: 10 14/60\n",
      "epoch: 10 21/60\n",
      "[11,    25] loss: 0.385\n",
      "epoch: 10 28/60\n",
      "epoch: 10 35/60\n",
      "epoch: 10 42/60\n",
      "[11,    50] loss: 0.291\n",
      "epoch: 10 49/60\n",
      "epoch: 10 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 62 %\n",
      "epoch: 11 0/60\n",
      "epoch: 11 7/60\n",
      "epoch: 11 14/60\n",
      "epoch: 11 21/60\n",
      "[12,    25] loss: 0.369\n",
      "epoch: 11 28/60\n",
      "epoch: 11 35/60\n",
      "epoch: 11 42/60\n",
      "[12,    50] loss: 0.287\n",
      "epoch: 11 49/60\n",
      "epoch: 11 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 62 %\n",
      "epoch: 12 0/60\n",
      "epoch: 12 7/60\n",
      "epoch: 12 14/60\n",
      "epoch: 12 21/60\n",
      "[13,    25] loss: 0.436\n",
      "epoch: 12 28/60\n",
      "epoch: 12 35/60\n",
      "epoch: 12 42/60\n",
      "[13,    50] loss: 0.288\n",
      "epoch: 12 49/60\n",
      "epoch: 12 56/60\n",
      "Accuracy train 83 %\n",
      "Accuracy test 62 %\n",
      "epoch: 13 0/60\n",
      "epoch: 13 7/60\n",
      "epoch: 13 14/60\n",
      "epoch: 13 21/60\n",
      "[14,    25] loss: 0.582\n",
      "epoch: 13 28/60\n",
      "epoch: 13 35/60\n",
      "epoch: 13 42/60\n",
      "[14,    50] loss: 0.368\n",
      "epoch: 13 49/60\n",
      "epoch: 13 56/60\n",
      "Accuracy train 83 %\n",
      "Accuracy test 65 %\n",
      "epoch: 14 0/60\n",
      "epoch: 14 7/60\n",
      "epoch: 14 14/60\n",
      "epoch: 14 21/60\n",
      "[15,    25] loss: 0.480\n",
      "epoch: 14 28/60\n",
      "epoch: 14 35/60\n",
      "epoch: 14 42/60\n",
      "[15,    50] loss: 0.329\n",
      "epoch: 14 49/60\n",
      "epoch: 14 56/60\n",
      "Accuracy train 84 %\n",
      "Accuracy test 65 %\n",
      "epoch: 15 0/60\n",
      "epoch: 15 7/60\n",
      "epoch: 15 14/60\n",
      "epoch: 15 21/60\n",
      "[16,    25] loss: 0.440\n",
      "epoch: 15 28/60\n",
      "epoch: 15 35/60\n",
      "epoch: 15 42/60\n",
      "[16,    50] loss: 0.307\n",
      "epoch: 15 49/60\n",
      "epoch: 15 56/60\n",
      "Accuracy train 84 %\n",
      "Accuracy test 58 %\n",
      "epoch: 16 0/60\n",
      "epoch: 16 7/60\n",
      "epoch: 16 14/60\n",
      "epoch: 16 21/60\n",
      "[17,    25] loss: 0.420\n",
      "epoch: 16 28/60\n",
      "epoch: 16 35/60\n",
      "epoch: 16 42/60\n",
      "[17,    50] loss: 0.292\n",
      "epoch: 16 49/60\n",
      "epoch: 16 56/60\n",
      "Accuracy train 86 %\n",
      "Accuracy test 65 %\n",
      "epoch: 17 0/60\n",
      "epoch: 17 7/60\n",
      "epoch: 17 14/60\n",
      "epoch: 17 21/60\n",
      "[18,    25] loss: 0.399\n",
      "epoch: 17 28/60\n",
      "epoch: 17 35/60\n",
      "epoch: 17 42/60\n",
      "[18,    50] loss: 0.283\n",
      "epoch: 17 49/60\n",
      "epoch: 17 56/60\n",
      "Accuracy train 86 %\n",
      "Accuracy test 68 %\n",
      "epoch: 18 0/60\n",
      "epoch: 18 7/60\n",
      "epoch: 18 14/60\n",
      "epoch: 18 21/60\n",
      "[19,    25] loss: 0.403\n",
      "epoch: 18 28/60\n",
      "epoch: 18 35/60\n",
      "epoch: 18 42/60\n",
      "[19,    50] loss: 0.283\n",
      "epoch: 18 49/60\n",
      "epoch: 18 56/60\n",
      "Accuracy train 87 %\n",
      "Accuracy test 72 %\n",
      "epoch: 19 0/60\n",
      "epoch: 19 7/60\n",
      "epoch: 19 14/60\n",
      "epoch: 19 21/60\n",
      "[20,    25] loss: 0.374\n",
      "epoch: 19 28/60\n",
      "epoch: 19 35/60\n",
      "epoch: 19 42/60\n",
      "[20,    50] loss: 0.252\n",
      "epoch: 19 49/60\n",
      "epoch: 19 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 65 %\n",
      "epoch: 20 0/60\n",
      "epoch: 20 7/60\n",
      "epoch: 20 14/60\n",
      "epoch: 20 21/60\n",
      "[21,    25] loss: 0.394\n",
      "epoch: 20 28/60\n",
      "epoch: 20 35/60\n",
      "epoch: 20 42/60\n",
      "[21,    50] loss: 0.246\n",
      "epoch: 20 49/60\n",
      "epoch: 20 56/60\n",
      "Accuracy train 87 %\n",
      "Accuracy test 62 %\n",
      "epoch: 21 0/60\n",
      "epoch: 21 7/60\n",
      "epoch: 21 14/60\n",
      "epoch: 21 21/60\n",
      "[22,    25] loss: 0.458\n",
      "epoch: 21 28/60\n",
      "epoch: 21 35/60\n",
      "epoch: 21 42/60\n",
      "[22,    50] loss: 0.290\n",
      "epoch: 21 49/60\n",
      "epoch: 21 56/60\n",
      "Accuracy train 87 %\n",
      "Accuracy test 68 %\n",
      "epoch: 22 0/60\n",
      "epoch: 22 7/60\n",
      "epoch: 22 14/60\n",
      "epoch: 22 21/60\n",
      "[23,    25] loss: 0.375\n",
      "epoch: 22 28/60\n",
      "epoch: 22 35/60\n",
      "epoch: 22 42/60\n",
      "[23,    50] loss: 0.260\n",
      "epoch: 22 49/60\n",
      "epoch: 22 56/60\n",
      "Accuracy train 87 %\n",
      "Accuracy test 62 %\n",
      "epoch: 23 0/60\n",
      "epoch: 23 7/60\n",
      "epoch: 23 14/60\n",
      "epoch: 23 21/60\n",
      "[24,    25] loss: 0.442\n",
      "epoch: 23 28/60\n",
      "epoch: 23 35/60\n",
      "epoch: 23 42/60\n",
      "[24,    50] loss: 0.271\n",
      "epoch: 23 49/60\n",
      "epoch: 23 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 44 %\n",
      "epoch: 24 0/60\n",
      "epoch: 24 7/60\n",
      "epoch: 24 14/60\n",
      "epoch: 24 21/60\n",
      "[25,    25] loss: 0.388\n",
      "epoch: 24 28/60\n",
      "epoch: 24 35/60\n",
      "epoch: 24 42/60\n",
      "[25,    50] loss: 0.266\n",
      "epoch: 24 49/60\n",
      "epoch: 24 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 65 %\n",
      "epoch: 25 0/60\n",
      "epoch: 25 7/60\n",
      "epoch: 25 14/60\n",
      "epoch: 25 21/60\n",
      "[26,    25] loss: 0.347\n",
      "epoch: 25 28/60\n",
      "epoch: 25 35/60\n",
      "epoch: 25 42/60\n",
      "[26,    50] loss: 0.240\n",
      "epoch: 25 49/60\n",
      "epoch: 25 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 65 %\n",
      "epoch: 26 0/60\n",
      "epoch: 26 7/60\n",
      "epoch: 26 14/60\n",
      "epoch: 26 21/60\n",
      "[27,    25] loss: 0.347\n",
      "epoch: 26 28/60\n",
      "epoch: 26 35/60\n",
      "epoch: 26 42/60\n",
      "[27,    50] loss: 0.252\n",
      "epoch: 26 49/60\n",
      "epoch: 26 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 72 %\n",
      "epoch: 27 0/60\n",
      "epoch: 27 7/60\n",
      "epoch: 27 14/60\n",
      "epoch: 27 21/60\n",
      "[28,    25] loss: 0.344\n",
      "epoch: 27 28/60\n",
      "epoch: 27 35/60\n",
      "epoch: 27 42/60\n",
      "[28,    50] loss: 0.254\n",
      "epoch: 27 49/60\n",
      "epoch: 27 56/60\n",
      "Accuracy train 88 %\n",
      "Accuracy test 65 %\n",
      "epoch: 28 0/60\n",
      "epoch: 28 7/60\n",
      "epoch: 28 14/60\n",
      "epoch: 28 21/60\n",
      "[29,    25] loss: 0.380\n",
      "epoch: 28 28/60\n",
      "epoch: 28 35/60\n",
      "epoch: 28 42/60\n",
      "[29,    50] loss: 0.230\n",
      "epoch: 28 49/60\n",
      "epoch: 28 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 72 %\n",
      "epoch: 29 0/60\n",
      "epoch: 29 7/60\n",
      "epoch: 29 14/60\n",
      "epoch: 29 21/60\n",
      "[30,    25] loss: 0.364\n",
      "epoch: 29 28/60\n",
      "epoch: 29 35/60\n",
      "epoch: 29 42/60\n",
      "[30,    50] loss: 0.235\n",
      "epoch: 29 49/60\n",
      "epoch: 29 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 68 %\n",
      "epoch: 30 0/60\n",
      "epoch: 30 7/60\n",
      "epoch: 30 14/60\n",
      "epoch: 30 21/60\n",
      "[31,    25] loss: 0.340\n",
      "epoch: 30 28/60\n",
      "epoch: 30 35/60\n",
      "epoch: 30 42/60\n",
      "[31,    50] loss: 0.246\n",
      "epoch: 30 49/60\n",
      "epoch: 30 56/60\n",
      "Accuracy train 90 %\n",
      "Accuracy test 65 %\n",
      "epoch: 31 0/60\n",
      "epoch: 31 7/60\n",
      "epoch: 31 14/60\n",
      "epoch: 31 21/60\n",
      "[32,    25] loss: 0.328\n",
      "epoch: 31 28/60\n",
      "epoch: 31 35/60\n",
      "epoch: 31 42/60\n",
      "[32,    50] loss: 0.244\n",
      "epoch: 31 49/60\n",
      "epoch: 31 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 72 %\n",
      "epoch: 32 0/60\n",
      "epoch: 32 7/60\n",
      "epoch: 32 14/60\n",
      "epoch: 32 21/60\n",
      "[33,    25] loss: 0.326\n",
      "epoch: 32 28/60\n",
      "epoch: 32 35/60\n",
      "epoch: 32 42/60\n",
      "[33,    50] loss: 0.227\n",
      "epoch: 32 49/60\n",
      "epoch: 32 56/60\n",
      "Accuracy train 90 %\n",
      "Accuracy test 72 %\n",
      "epoch: 33 0/60\n",
      "epoch: 33 7/60\n",
      "epoch: 33 14/60\n",
      "epoch: 33 21/60\n",
      "[34,    25] loss: 0.327\n",
      "epoch: 33 28/60\n",
      "epoch: 33 35/60\n",
      "epoch: 33 42/60\n",
      "[34,    50] loss: 0.229\n",
      "epoch: 33 49/60\n",
      "epoch: 33 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 65 %\n",
      "epoch: 34 0/60\n",
      "epoch: 34 7/60\n",
      "epoch: 34 14/60\n",
      "epoch: 34 21/60\n",
      "[35,    25] loss: 0.303\n",
      "epoch: 34 28/60\n",
      "epoch: 34 35/60\n",
      "epoch: 34 42/60\n",
      "[35,    50] loss: 0.233\n",
      "epoch: 34 49/60\n",
      "epoch: 34 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 58 %\n",
      "epoch: 35 0/60\n",
      "epoch: 35 7/60\n",
      "epoch: 35 14/60\n",
      "epoch: 35 21/60\n",
      "[36,    25] loss: 0.320\n",
      "epoch: 35 28/60\n",
      "epoch: 35 35/60\n",
      "epoch: 35 42/60\n",
      "[36,    50] loss: 0.240\n",
      "epoch: 35 49/60\n",
      "epoch: 35 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 65 %\n",
      "epoch: 36 0/60\n",
      "epoch: 36 7/60\n",
      "epoch: 36 14/60\n",
      "epoch: 36 21/60\n",
      "[37,    25] loss: 0.330\n",
      "epoch: 36 28/60\n",
      "epoch: 36 35/60\n",
      "epoch: 36 42/60\n",
      "[37,    50] loss: 0.220\n",
      "epoch: 36 49/60\n",
      "epoch: 36 56/60\n",
      "Accuracy train 90 %\n",
      "Accuracy test 65 %\n",
      "epoch: 37 0/60\n",
      "epoch: 37 7/60\n",
      "epoch: 37 14/60\n",
      "epoch: 37 21/60\n",
      "[38,    25] loss: 0.292\n",
      "epoch: 37 28/60\n",
      "epoch: 37 35/60\n",
      "epoch: 37 42/60\n",
      "[38,    50] loss: 0.226\n",
      "epoch: 37 49/60\n",
      "epoch: 37 56/60\n",
      "Accuracy train 89 %\n",
      "Accuracy test 62 %\n",
      "epoch: 38 0/60\n",
      "epoch: 38 7/60\n",
      "epoch: 38 14/60\n",
      "epoch: 38 21/60\n",
      "[39,    25] loss: 0.317\n",
      "epoch: 38 28/60\n",
      "epoch: 38 35/60\n",
      "epoch: 38 42/60\n",
      "[39,    50] loss: 0.213\n",
      "epoch: 38 49/60\n",
      "epoch: 38 56/60\n",
      "Accuracy train 90 %\n",
      "Accuracy test 75 %\n",
      "epoch: 39 0/60\n",
      "epoch: 39 7/60\n",
      "epoch: 39 14/60\n",
      "epoch: 39 21/60\n",
      "[40,    25] loss: 0.310\n",
      "epoch: 39 28/60\n",
      "epoch: 39 35/60\n",
      "epoch: 39 42/60\n",
      "[40,    50] loss: 0.222\n",
      "epoch: 39 49/60\n",
      "epoch: 39 56/60\n",
      "Accuracy train 90 %\n",
      "Accuracy test 72 %\n",
      "Training is done\n",
      "Total Training Time (second): 1981.2950401306152\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "train_acc = []\n",
    "start = time.time()\n",
    "loss_list = []\n",
    "running_loss = 0\n",
    "total_step = len(trainloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):       \n",
    "        # gpu\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "            \n",
    "        \n",
    "        # backward and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 25 == 24: # print every 500 mini batches\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i+1,running_loss/25))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        if i % 7 == 0:\n",
    "            print(\"epoch: {} {}/{}\".format(epoch,i,total_step))\n",
    "\n",
    "\n",
    "    # train\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy train %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    # test\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data      \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)                \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy test %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "\n",
    "end= time.time()\n",
    "stopWatch = end-start\n",
    "print( \"Training is done\")\n",
    "print('Total Training Time (second):',stopWatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2249e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['good','broke','shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "837a52ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 1.000000\n",
      "Accuracy score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "def test_label_predictions(model, device, test_loader):\n",
    "    model.eval()\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            actuals.extend(target.view_as(prediction))\n",
    "            predictions.extend(prediction)\n",
    "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
    "\n",
    "actuals, predictions = test_label_predictions(model, device, testloader)\n",
    "print('F1 score: %f' % f1_score(actuals, predictions, average='weighted'))\n",
    "print('Accuracy score: %f' % accuracy_score(actuals, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d55bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_251779/3249040878.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + classes)\n",
      "/tmp/ipykernel_251779/3249040878.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + classes)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1728 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(actuals, predictions)\n",
    "print(cm)\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "ax = fig.add_subplot(211)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + classes)\n",
    "ax.set_yticklabels([''] + classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3422bd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 3. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_251779/1878998717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2565\u001b[0m             )\n\u001b[1;32m   2566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2567\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2568\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2569\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 3. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    " print(classification_report(actuals, predictions, target_names=classes, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a27e5e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['broke', 'good', 'shift']\n",
      "train Dataset size: 9595\n",
      "test Dataset size: 29\n"
     ]
    }
   ],
   "source": [
    "batch_size=256\n",
    "\n",
    "train_dataset = ImageFolder(root='/root/notebooks/nfs/work/barry.chen/DenoisingDiffusionProbabilityModel-ddpm-/dataset/only_group1', transform=transform)\n",
    "test_dataset = ImageFolder(root='/root/notebooks/nfs/work/barry.chen/DenoisingDiffusionProbabilityModel-ddpm-/dataset/broke_F1210', transform=transform_test)\n",
    "# test_dataset = ImageFolder(root='/root/notebooks/nfs/work/barry.chen/Phison/Conditional_Diffusion/CDDIM/select', transform=transform)\n",
    "# # 創建 DataLoader\n",
    "# # 分割數據集\n",
    "# train_size = int(0.8 * len(dataset))  # 假設80%用於訓練\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 創建 DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# 檢查數據集的類別\n",
    "classes = train_dataset.classes\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "\n",
    "# 顯示數據集的大小\n",
    "print(\"train Dataset size:\", len(train_dataset))\n",
    "print(\"test Dataset size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a79c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet152()\n",
    "model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 3),\n",
    "    )\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afe33199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 0/38\n",
      "epoch: 0 7/38\n",
      "epoch: 0 14/38\n",
      "epoch: 0 21/38\n",
      "[1,    25] loss: 0.838\n",
      "epoch: 0 28/38\n",
      "epoch: 0 35/38\n",
      "Accuracy train 54 %\n",
      "Accuracy test 0 %\n",
      "epoch: 1 0/38\n",
      "epoch: 1 7/38\n",
      "epoch: 1 14/38\n",
      "epoch: 1 21/38\n",
      "[2,    25] loss: 1.176\n",
      "epoch: 1 28/38\n",
      "epoch: 1 35/38\n",
      "Accuracy train 62 %\n",
      "Accuracy test 0 %\n",
      "epoch: 2 0/38\n",
      "epoch: 2 7/38\n",
      "epoch: 2 14/38\n",
      "epoch: 2 21/38\n",
      "[3,    25] loss: 1.052\n",
      "epoch: 2 28/38\n",
      "epoch: 2 35/38\n",
      "Accuracy train 63 %\n",
      "Accuracy test 0 %\n",
      "epoch: 3 0/38\n",
      "epoch: 3 7/38\n",
      "epoch: 3 14/38\n",
      "epoch: 3 21/38\n",
      "[4,    25] loss: 1.014\n",
      "epoch: 3 28/38\n",
      "epoch: 3 35/38\n",
      "Accuracy train 68 %\n",
      "Accuracy test 0 %\n",
      "epoch: 4 0/38\n",
      "epoch: 4 7/38\n",
      "epoch: 4 14/38\n",
      "epoch: 4 21/38\n",
      "[5,    25] loss: 0.956\n",
      "epoch: 4 28/38\n",
      "epoch: 4 35/38\n",
      "Accuracy train 69 %\n",
      "Accuracy test 0 %\n",
      "epoch: 5 0/38\n",
      "epoch: 5 7/38\n",
      "epoch: 5 14/38\n",
      "epoch: 5 21/38\n",
      "[6,    25] loss: 0.920\n",
      "epoch: 5 28/38\n",
      "epoch: 5 35/38\n",
      "Accuracy train 70 %\n",
      "Accuracy test 0 %\n",
      "epoch: 6 0/38\n",
      "epoch: 6 7/38\n",
      "epoch: 6 14/38\n",
      "epoch: 6 21/38\n",
      "[7,    25] loss: 0.884\n",
      "epoch: 6 28/38\n",
      "epoch: 6 35/38\n",
      "Accuracy train 71 %\n",
      "Accuracy test 0 %\n",
      "epoch: 7 0/38\n",
      "epoch: 7 7/38\n",
      "epoch: 7 14/38\n",
      "epoch: 7 21/38\n",
      "[8,    25] loss: 0.868\n",
      "epoch: 7 28/38\n",
      "epoch: 7 35/38\n",
      "Accuracy train 72 %\n",
      "Accuracy test 0 %\n",
      "epoch: 8 0/38\n",
      "epoch: 8 7/38\n",
      "epoch: 8 14/38\n",
      "epoch: 8 21/38\n",
      "[9,    25] loss: 0.847\n",
      "epoch: 8 28/38\n",
      "epoch: 8 35/38\n",
      "Accuracy train 75 %\n",
      "Accuracy test 0 %\n",
      "epoch: 9 0/38\n",
      "epoch: 9 7/38\n",
      "epoch: 9 14/38\n",
      "epoch: 9 21/38\n",
      "[10,    25] loss: 0.792\n",
      "epoch: 9 28/38\n",
      "epoch: 9 35/38\n",
      "Accuracy train 76 %\n",
      "Accuracy test 0 %\n",
      "epoch: 10 0/38\n",
      "epoch: 10 7/38\n",
      "epoch: 10 14/38\n",
      "epoch: 10 21/38\n",
      "[11,    25] loss: 0.784\n",
      "epoch: 10 28/38\n",
      "epoch: 10 35/38\n",
      "Accuracy train 77 %\n",
      "Accuracy test 0 %\n",
      "epoch: 11 0/38\n",
      "epoch: 11 7/38\n",
      "epoch: 11 14/38\n",
      "epoch: 11 21/38\n",
      "[12,    25] loss: 0.759\n",
      "epoch: 11 28/38\n",
      "epoch: 11 35/38\n",
      "Accuracy train 77 %\n",
      "Accuracy test 0 %\n",
      "epoch: 12 0/38\n",
      "epoch: 12 7/38\n",
      "epoch: 12 14/38\n",
      "epoch: 12 21/38\n",
      "[13,    25] loss: 0.765\n",
      "epoch: 12 28/38\n",
      "epoch: 12 35/38\n",
      "Accuracy train 77 %\n",
      "Accuracy test 0 %\n",
      "epoch: 13 0/38\n",
      "epoch: 13 7/38\n",
      "epoch: 13 14/38\n",
      "epoch: 13 21/38\n",
      "[14,    25] loss: 0.745\n",
      "epoch: 13 28/38\n",
      "epoch: 13 35/38\n",
      "Accuracy train 78 %\n",
      "Accuracy test 0 %\n",
      "epoch: 14 0/38\n",
      "epoch: 14 7/38\n",
      "epoch: 14 14/38\n",
      "epoch: 14 21/38\n",
      "[15,    25] loss: 0.717\n",
      "epoch: 14 28/38\n",
      "epoch: 14 35/38\n",
      "Accuracy train 78 %\n",
      "Accuracy test 0 %\n",
      "epoch: 15 0/38\n",
      "epoch: 15 7/38\n",
      "epoch: 15 14/38\n",
      "epoch: 15 21/38\n",
      "[16,    25] loss: 0.736\n",
      "epoch: 15 28/38\n",
      "epoch: 15 35/38\n",
      "Accuracy train 80 %\n",
      "Accuracy test 0 %\n",
      "epoch: 16 0/38\n",
      "epoch: 16 7/38\n",
      "epoch: 16 14/38\n",
      "epoch: 16 21/38\n",
      "[17,    25] loss: 0.705\n",
      "epoch: 16 28/38\n",
      "epoch: 16 35/38\n",
      "Accuracy train 80 %\n",
      "Accuracy test 0 %\n",
      "epoch: 17 0/38\n",
      "epoch: 17 7/38\n",
      "epoch: 17 14/38\n",
      "epoch: 17 21/38\n",
      "[18,    25] loss: 0.705\n",
      "epoch: 17 28/38\n",
      "epoch: 17 35/38\n",
      "Accuracy train 79 %\n",
      "Accuracy test 0 %\n",
      "epoch: 18 0/38\n",
      "epoch: 18 7/38\n",
      "epoch: 18 14/38\n",
      "epoch: 18 21/38\n",
      "[19,    25] loss: 0.732\n",
      "epoch: 18 28/38\n",
      "epoch: 18 35/38\n",
      "Accuracy train 80 %\n",
      "Accuracy test 0 %\n",
      "epoch: 19 0/38\n",
      "epoch: 19 7/38\n",
      "epoch: 19 14/38\n",
      "epoch: 19 21/38\n",
      "[20,    25] loss: 0.666\n",
      "epoch: 19 28/38\n",
      "epoch: 19 35/38\n",
      "Accuracy train 80 %\n",
      "Accuracy test 0 %\n",
      "epoch: 20 0/38\n",
      "epoch: 20 7/38\n",
      "epoch: 20 14/38\n",
      "epoch: 20 21/38\n",
      "[21,    25] loss: 0.670\n",
      "epoch: 20 28/38\n",
      "epoch: 20 35/38\n",
      "Accuracy train 82 %\n",
      "Accuracy test 0 %\n",
      "epoch: 21 0/38\n",
      "epoch: 21 7/38\n",
      "epoch: 21 14/38\n",
      "epoch: 21 21/38\n",
      "[22,    25] loss: 0.663\n",
      "epoch: 21 28/38\n",
      "epoch: 21 35/38\n",
      "Accuracy train 81 %\n",
      "Accuracy test 0 %\n",
      "epoch: 22 0/38\n",
      "epoch: 22 7/38\n",
      "epoch: 22 14/38\n",
      "epoch: 22 21/38\n",
      "[23,    25] loss: 0.677\n",
      "epoch: 22 28/38\n",
      "epoch: 22 35/38\n",
      "Accuracy train 81 %\n",
      "Accuracy test 0 %\n",
      "epoch: 23 0/38\n",
      "epoch: 23 7/38\n",
      "epoch: 23 14/38\n",
      "epoch: 23 21/38\n",
      "[24,    25] loss: 0.640\n",
      "epoch: 23 28/38\n",
      "epoch: 23 35/38\n",
      "Accuracy train 81 %\n",
      "Accuracy test 0 %\n",
      "epoch: 24 0/38\n",
      "epoch: 24 7/38\n",
      "epoch: 24 14/38\n",
      "epoch: 24 21/38\n",
      "[25,    25] loss: 0.645\n",
      "epoch: 24 28/38\n",
      "epoch: 24 35/38\n",
      "Accuracy train 82 %\n",
      "Accuracy test 0 %\n",
      "epoch: 25 0/38\n",
      "epoch: 25 7/38\n",
      "epoch: 25 14/38\n",
      "epoch: 25 21/38\n",
      "[26,    25] loss: 0.638\n",
      "epoch: 25 28/38\n",
      "epoch: 25 35/38\n",
      "Accuracy train 83 %\n",
      "Accuracy test 0 %\n",
      "epoch: 26 0/38\n",
      "epoch: 26 7/38\n",
      "epoch: 26 14/38\n",
      "epoch: 26 21/38\n",
      "[27,    25] loss: 0.624\n",
      "epoch: 26 28/38\n",
      "epoch: 26 35/38\n",
      "Accuracy train 82 %\n",
      "Accuracy test 0 %\n",
      "epoch: 27 0/38\n",
      "epoch: 27 7/38\n",
      "epoch: 27 14/38\n",
      "epoch: 27 21/38\n",
      "[28,    25] loss: 0.627\n",
      "epoch: 27 28/38\n",
      "epoch: 27 35/38\n",
      "Accuracy train 82 %\n",
      "Accuracy test 0 %\n",
      "epoch: 28 0/38\n",
      "epoch: 28 7/38\n",
      "epoch: 28 14/38\n",
      "epoch: 28 21/38\n",
      "[29,    25] loss: 0.599\n",
      "epoch: 28 28/38\n",
      "epoch: 28 35/38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_251779/2777563530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy train %d %%\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "train_acc = []\n",
    "start = time.time()\n",
    "loss_list = []\n",
    "running_loss = 0\n",
    "total_step = len(trainloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):       \n",
    "        # gpu\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        outputs = model(images)\n",
    "         \n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "            \n",
    "        \n",
    "        # backward and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 25 == 24: # print every 500 mini batches\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i+1,running_loss/25))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        if i % 7 == 0:\n",
    "            print(\"epoch: {} {}/{}\".format(epoch,i,total_step))\n",
    "\n",
    "\n",
    "    # train\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy train %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    # test\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data      \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)                \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy test %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "\n",
    "end= time.time()\n",
    "stopWatch = end-start\n",
    "print( \"Training is done\")\n",
    "print('Total Training Time (second):',stopWatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e507c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
